import torch
import whisperx
import json
import os
import subprocess
import re

# -----------------------
# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ÙˆØ§Ù„Ù…Ù„ÙØ§Øª
# -----------------------
AUDIO_PATH = r"C:\Users\TOSHIBA\PycharmProjects\Amk1\generated_audios\trump_voice.wav"
TEXT_FILE = r"C:\Users\TOSHIBA\PycharmProjects\Amk1\documentary_intro.txt"

with open(TEXT_FILE, "r", encoding="utf-8") as f:
    TEXT = f.read().strip()

# -----------------------
# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù„ØºØ© ÙˆØ§Ù„Ù†Ù…ÙˆØ°Ø¬
# -----------------------
LANG_CODE = "en"      # Ø±Ù…Ø² Ø§Ù„Ù„ØºØ© Ù„Ù„Ù€ WhisperX (Ù…Ø«Ù„: en, ar, fr)
ESPEAK_LANG = "en-us" # Ø±Ù…Ø² Ø§Ù„Ù„ØºØ© Ù„Ù€ eSpeak-NG (Ù…Ø«Ù„: en-us, fr, ar)
MODEL_SIZE = "small"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# Ù…Ø³Ø§Ø± espeak-ng.exe ÙˆØ¨ÙŠØ§Ù†Ø§ØªÙ‡
ESPEAK_PATH = r"C:\Program Files\eSpeak_NG\espeak-ng.exe"
ESPEAK_DATA_PATH = r"C:\Program Files\eSpeak_NG\espeak-ng-data"
os.environ["PHONEMIZER_ESPEAK_PATH"] = ESPEAK_PATH
os.environ["ESPEAK_DATA_PATH"] = ESPEAK_DATA_PATH

# -----------------------
# Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©
# -----------------------
def whisperx_transcribe_and_align(audio_path, model_size, device, language="en"):
    compute_type = "float16" if device == "cuda" else "float32"
    model = whisperx.load_model(model_size, device, language=language, compute_type=compute_type)
    audio = whisperx.load_audio(audio_path)
    result = model.transcribe(audio)
    model_a, metadata = whisperx.load_align_model(language_code=language, device=device)
    result_aligned = whisperx.align(result["segments"], model_a, metadata, audio, device)
    return result_aligned

def get_word_timestamps_from_whisperx(result):
    words = []
    for seg in result["segments"]:
        for w in seg["words"]:
            words.append({
                "word": w["word"],
                "start": w["start"],
                "end": w["end"]
            })
    return words

def phonemize_word_with_espeak(word, lang=ESPEAK_LANG):
    """
    Ø§Ø³ØªØ®Ø¯Ø§Ù… eSpeak-NG Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ÙÙˆÙ†ÙŠÙ…Ø§Øª ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø© Ø¨Ù„ØºØ© Ù…Ø­Ø¯Ø¯Ø©.
    """
    try:
        output = subprocess.check_output(
            [ESPEAK_PATH, "-q", "-x", f"-v{lang}", word],
            stderr=subprocess.DEVNULL,
            encoding="utf-8"
        )
        phonemes = output.strip().split()
        return phonemes
    except Exception as e:
        print(f"Error phonemizing {word}: {e}")
        return []

def split_phonemes(phoneme_str):
    """
    ØªÙ‚Ø³ÙŠÙ… ÙÙˆÙ†ÙŠÙ… Ù…Ø±ÙƒØ¨ Ø¥Ù„Ù‰ ÙÙˆÙ†ÙŠÙ…Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø©.
    Ù…Ø«Ø§Ù„: "h@l'oU" -> ['h', '@', 'l', 'oU']
    """
    phonemes = re.findall(r"[a-zA-Z]+[:@3]*|'[a-zA-Z]+", phoneme_str)
    return phonemes

def phonemize_words(words, espeak_lang=ESPEAK_LANG):
    """
    Ø¥Ù†Ø´Ø§Ø¡ JSON Ø¯Ù‚ÙŠÙ‚ Ù„ÙƒÙ„ ÙÙˆÙ†ÙŠÙ… ÙØ±Ø¯ÙŠ Ù…Ø¹ Ø§Ù„ØªÙˆÙ‚ÙŠØª.
    """
    results = []
    vowels = "aeiouAEIOU@3:"

    for w in words:
        phonemes_raw = phonemize_word_with_espeak(w["word"], lang=espeak_lang)
        if not phonemes_raw:
            continue

        # ØªÙ‚Ø³ÙŠÙ… ÙƒÙ„ ÙÙˆÙ†ÙŠÙ… Ù…Ø±ÙƒØ¨ Ø¥Ù„Ù‰ ÙÙˆÙ†ÙŠÙ…Ø§Øª ÙØ±Ø¯ÙŠØ©
        phonemes = []
        for p in phonemes_raw:
            phonemes.extend(split_phonemes(p))

        total_duration = w["end"] - w["start"]
        weights = [1.5 if any(v in p for v in vowels) else 1.0 for p in phonemes]
        weight_sum = sum(weights)

        start_time = w["start"]
        for i, p in enumerate(phonemes):
            dur = total_duration * (weights[i] / weight_sum)
            if dur >= 0.01:
                results.append({
                    "phoneme": p,
                    "word": w["word"],
                    "start": round(start_time, 3),
                    "end": round(start_time + dur, 3)
                })
            start_time += dur
    return results

# -----------------------
# Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
# -----------------------
def main():
    print("ðŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©...")
    result = whisperx_transcribe_and_align(AUDIO_PATH, MODEL_SIZE, DEVICE, language=LANG_CODE)
    words = get_word_timestamps_from_whisperx(result)

    # Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø¨Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ
    manual_words = TEXT.split()
    for i, w in enumerate(words):
        if i < len(manual_words):
            w["word"] = manual_words[i]

    phoneme_timings = phonemize_words(words, espeak_lang=ESPEAK_LANG)

    with open("phoneme_timing.json", "w", encoding="utf-8") as f:
        json.dump(phoneme_timings, f, ensure_ascii=False, indent=2)

    print("âœ… ØªÙ… Ø§Ù„Ø­ÙØ¸ ÙÙŠ phoneme_timing.json")

if __name__ == "__main__":
    main()
