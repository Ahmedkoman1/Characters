import whisper
import pyaudio
import wave
import os
import tempfile

model = whisper.load_model("medium")  # ÙŠÙ…ÙƒÙ†Ùƒ ØªØºÙŠÙŠØ±Ù‡ Ù„Ù€ 'small' Ø£Ùˆ 'medium'

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ³Ø¬ÙŠÙ„
CHUNK = 1024
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
RECORD_SECONDS = 5  # Ù…Ø¯Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„

def record_audio(file_path):
    audio = pyaudio.PyAudio()

    print("ğŸ™ï¸ ØªØ³Ø¬ÙŠÙ„ Ø¬Ø§Ø±ÙŠ... ØªØ­Ø¯Ø« Ø§Ù„Ø¢Ù†")

    stream = audio.open(format=FORMAT, channels=CHANNELS,
                        rate=RATE, input=True,
                        frames_per_buffer=CHUNK)

    frames = []

    for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):
        data = stream.read(CHUNK)
        frames.append(data)

    print("âœ… ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØªØŒ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù†Øµ...")

    stream.stop_stream()
    stream.close()
    audio.terminate()

    wf = wave.open(file_path, 'wb')
    wf.setnchannels(CHANNELS)
    wf.setsampwidth(audio.get_sample_size(FORMAT))
    wf.setframerate(RATE)
    wf.writeframes(b''.join(frames))
    wf.close()


def transcribe_audio(path):
    result = model.transcribe(path)
    print("ğŸ“ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙƒØªØ´Ù:")
    print(result["text"])


if __name__ == "__main__":
    input("Ø§Ø¶ØºØ· Enter Ù„Ø¨Ø¯Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙˆØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ...")

    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmpfile:
        audio_path = tmpfile.name

    record_audio(audio_path)
    transcribe_audio(audio_path)

    os.remove(audio_path)
